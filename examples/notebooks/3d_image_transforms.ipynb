{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "This notebook introduces you MONAI's image transformation module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2020 MONAI Consortium\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import monai\n",
    "from monai.transforms import \\\n",
    "    LoadNifti, LoadNiftid, AddChanneld, ScaleIntensityRanged, \\\n",
    "    Rand3DElasticd, RandAffined, \\\n",
    "    Spacingd, Orientationd\n",
    "\n",
    "monai.config.print_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data sources\n",
    "Starting from a list of filenames. The Spleen dataset can be downloaded from http://medicaldecathlon.com/.\n",
    "\n",
    "The following is a simple python script\n",
    "to group pairs of image and label from `Task09_Spleen/imagesTr` and `Task09_Spleen/labelsTr`\n",
    "folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = '/workspace/data/medical/Task09_Spleen'\n",
    "\n",
    "import os\n",
    "import glob\n",
    "train_images = sorted(glob.glob(os.path.join(data_root, 'imagesTr', '*.nii.gz')))\n",
    "train_labels = sorted(glob.glob(os.path.join(data_root, 'labelsTr', '*.nii.gz')))\n",
    "data_dicts = [{'image': image_name, 'label': label_name}\n",
    "              for image_name, label_name in zip(train_images, train_labels)]\n",
    "train_data_dicts, val_data_dicts = data_dicts[:-9], data_dicts[-9:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image file names are organised into a list of dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dicts[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list of data dictionaries, `train_data_dicts`, could be used by\n",
    "PyTorch's data loader.\n",
    "\n",
    "For example,\n",
    "\n",
    "```python\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "data_loader = DataLoader(train_data_dicts)\n",
    "for training_sample in data_loader:\n",
    "    # run the deep learning training with training_sample\n",
    "```\n",
    "\n",
    "The rest of this tutorial presents a set of \"transforms\"\n",
    "converting `train_data_dict` into data arrays that\n",
    "will eventually be consumed by the deep learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the NIfTI files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One design choice of MONAI is that it provides not only the high-level workflow components,\n",
    "but also relatively lower level APIs in their minimal functioning form.\n",
    "\n",
    "For example, a `LoadNifti` class is a simple callable wrapper of the underlying `Nibabel` image loader.\n",
    "After constructing the loader with a few necessary system parameters,\n",
    "calling the loader instance with a NIfTI filename will return the image data arrays, as well as the metadata -- such as affine information and voxel sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = LoadNifti(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, metadata = loader(train_data_dicts[0]['image'])\n",
    "print(f\"input: {train_data_dicts[0]['image']}\")\n",
    "print(f\"image shape: {image.shape}\")\n",
    "print(f\"image affine:\\n{metadata['affine']}\")\n",
    "print(f\"image pixdim:\\n{metadata['pixdim']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oftentimes, we want to load a group of inputs as a training sample.\n",
    "For example training a supervised image segmentation network requires a pair of image and label as a training sample.\n",
    "\n",
    "To ensure a group of inputs are beining preprocessed consistently,\n",
    "MONAI also provides dictionary-based interfaces for the minimal functioning transforms.\n",
    "\n",
    "`LoadNiftid` is the corresponding dict-based version of `LoadNifti`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = LoadNiftid(keys=('image', 'label'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = loader(train_data_dicts[0])\n",
    "print(f\"input:, {train_data_dicts[0]}\")\n",
    "print(f\"image shape: {data_dict['image'].shape}\")\n",
    "print(f\"label shape: {data_dict['label'].shape}\")\n",
    "print(f\"image pixdim:\\n{data_dict['image_meta_dict']['pixdim']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = data_dict['image'], data_dict['label']\n",
    "plt.figure('visualize', (8, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('image')\n",
    "plt.imshow(image[:, :, 30], cmap='gray')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('label')\n",
    "plt.imshow(label[:, :, 30])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add the channel dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of MONAI's image transformations assume that the input data has the shape:\n",
    "\n",
    "`[num_channels, spatial_dim_1, spatial_dim_2, ... ,spatial_dim_n]`\n",
    "\n",
    "so that they could be interpreted consistently (as \"channel-first\" is commonly used in PyTorch).\n",
    "\n",
    "Here the input image has shape `(512, 512, 55)` which isn't in the acceptable shape (missing the channel dimension),\n",
    "\n",
    "we therefore create a transform which is called to update the shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_channel = AddChanneld(keys=['image', 'label'])\n",
    "datac_dict = add_channel(data_dict)\n",
    "print(f\"image shape: {datac_dict['image'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to do some intensity and spatial transforms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resample to a consistent voxel size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input volumes might have different voxel sizes.\n",
    "\n",
    "The following transform is created to normalise the volumes to have (1.5, 1.5, 5.) millimetre voxel size.\n",
    "\n",
    "The transform is set to read the original voxel size information from `data_dict['image.affine']`,\n",
    "which is from the corresponding NIfTI file, loaded earlier by `LoadNiftid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacing = Spacingd(keys=['image', 'label'], pixdim=(1.5, 1.5, 5.), mode=('bilinear', 'nearest'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = spacing(datac_dict)\n",
    "print(f\"image shape: {data_dict['image'].shape}\")\n",
    "print(f\"label shape: {data_dict['label'].shape}\")\n",
    "print(f\"image affine after Spacing:\\n{data_dict['image_meta_dict']['affine']}\") \n",
    "print(f\"label affine after Spacing:\\n{data_dict['label_meta_dict']['affine']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To track the spacing changes, the data_dict was updated by `Spacingd`:\n",
    "\n",
    "- An `image.original_affine` key is added to the `data_dict`, logs the original affine.\n",
    "\n",
    "- An `image.affine` key is updated to have the current affine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = data_dict['image'], data_dict['label']\n",
    "plt.figure('visualise', (8, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('image')\n",
    "plt.imshow(image[0, :, :, 30], cmap='gray')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('label')\n",
    "plt.imshow(label[0, :, :, 30])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reorientation to a designated axes codes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes it is nice to have all the input volumes in a consistent axes orientation.\n",
    "\n",
    "The default axis labels are Left (L), Right (R), Posterior (P), Anterior (A), Inferior (I), Superior (S).\n",
    "\n",
    "The following transform is created to reorientate the volumes to have 'Posterior, Left, Inferior' (PLI) orientation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacing = Orientationd(keys=['image', 'label'], axcodes='PLI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = spacing(data_dict)\n",
    "print(f\"image shape: {data_dict['image'].shape}\")\n",
    "print(f\"label shape: {data_dict['label'].shape}\")\n",
    "print(f\"image affine after Spacing:\\n{data_dict['image_meta_dict']['affine']}\") \n",
    "print(f\"label affine after Spacing:\\n{data_dict['label_meta_dict']['affine']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = data_dict['image'], data_dict['label']\n",
    "plt.figure('visualise', (8, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('image')\n",
    "plt.imshow(image[0, :, :, 30], cmap='gray')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('label')\n",
    "plt.imshow(label[0, :, :, 30])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random affine transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following affine transformation is defined to output a (300, 300, 50) image patch.\n",
    "\n",
    "The patch location is randomly chosen in a range of (-40, 40), (-40, 40), (-2, 2) in x, y, and z axes respectively.\n",
    "The translation is relative to the image centre.\n",
    "\n",
    "The 3D rotation angle is randomly chosen from (-45, 45) degrees around the z axis, and 5 degrees around x and y axes.\n",
    "\n",
    "The random scaling factor is randomly chosen from (1.0 - 0.15, 1.0 + 0.15) along each axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_affine = RandAffined(keys=['image', 'label'], mode=('bilinear', 'nearest'), prob=1.0,\n",
    "                          spatial_size=(300, 300, 50),\n",
    "                          translate_range=(40, 40, 2),\n",
    "                          rotate_range=(np.pi/36, np.pi/36, np.pi*4),\n",
    "                          scale_range=(0.15, 0.15, 0.15),\n",
    "                          padding_mode='border')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can rerun this cell to generate a different randomised version of the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "affined_data_dict = rand_affine(data_dict)\n",
    "print(f\"image shape: {affined_data_dict['image'].shape}\")\n",
    "\n",
    "image, label = affined_data_dict['image'][0], affined_data_dict['label'][0]\n",
    "plt.figure('visualise', (12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('image')\n",
    "plt.imshow(image[:, :, 15], cmap='gray')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('label')\n",
    "plt.imshow(label[:, :, 15])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random elastic deformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, the following elastic deformation is defined to output a (300, 300, 10) image patch.\n",
    "\n",
    "The image is resampled from a combination of affine transformations and elastic deformations.\n",
    "\n",
    "`sigma_range` controls the smoothness of the deformation (larger than 15 could be slow on CPU)\n",
    "\n",
    "`magnitude_range` controls the amplitude of the deformation (large than 500, the image becomes unrealistic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_elastic = Rand3DElasticd(\n",
    "    keys=['image', 'label'], mode=('bilinear', 'nearest'), prob=1.0,\n",
    "    sigma_range=(5, 8),\n",
    "    magnitude_range=(100, 200),\n",
    "    spatial_size=(300, 300, 10),\n",
    "    translate_range=(50, 50, 2),\n",
    "    rotate_range=(np.pi/36, np.pi/36, np.pi*2),\n",
    "    scale_range=(0.15, 0.15, 0.15),\n",
    "    padding_mode='border')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can rerun this cell to generate a different randomised version of the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deformed_data_dict = rand_elastic(data_dict)\n",
    "print(f\"image shape: {deformed_data_dict['image'].shape}\")\n",
    "\n",
    "image, label = deformed_data_dict['image'][0], deformed_data_dict['label'][0]\n",
    "plt.figure('visualise', (12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('image')\n",
    "plt.imshow(image[:, :, 5], cmap='gray')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('label')\n",
    "plt.imshow(label[:, :, 5])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}