{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import time\n",
    "\n",
    "import torch\n",
    "\n",
    "from monai.apps.deepgrow import (\n",
    "    AddInitialSeedPoint,\n",
    "    AddGuidanceSignal,\n",
    "    InteractionFindDiscrepancyRegions,\n",
    "    InteractionAddRandomGuidance,\n",
    "    InteractionAddGuidanceSignal,\n",
    "    Interaction,\n",
    "    DeepgrowStatsHandler,\n",
    "    DeepgrowDataset\n",
    ")\n",
    "from monai.data.dataloader import DataLoader\n",
    "from monai.engines import SupervisedEvaluator\n",
    "from monai.engines import SupervisedTrainer\n",
    "from monai.handlers import (\n",
    "    StatsHandler,\n",
    "    TensorBoardStatsHandler,\n",
    "    ValidationHandler,\n",
    "    LrScheduleHandler,\n",
    "    CheckpointSaver,\n",
    "    MeanDice)\n",
    "from monai.inferers import SimpleInferer\n",
    "from monai.losses import DiceLoss\n",
    "from monai.networks.nets import BasicUnet\n",
    "from monai.transforms import (\n",
    "    Compose,\n",
    "    LoadNumpyd,\n",
    "    AddChanneld,\n",
    "    ToTensord,\n",
    "    ToNumpyd,\n",
    "    NormalizeIntensityd,\n",
    "    Activationsd,\n",
    "    AsDiscreted,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.environ.get(\"MONAI_DATA_DIRECTORY\", '/workspace/Data/deepgrow_spleen')\n",
    "root_dir = tempfile.mkdtemp() if directory is None else directory\n",
    "os.makedirs(root_dir, exist_ok=True)\n",
    "print(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = BasicUnet(dimensions=2, in_channels=3, out_channels=1, features=(64, 128, 256, 512, 1024, 64))\n",
    "\n",
    "pre_transforms = Compose([\n",
    "    LoadNumpyd(keys=('image', 'label')),\n",
    "    AddChanneld(keys=('image', 'label')),\n",
    "    AddInitialSeedPoint(\n",
    "        label_field='label',\n",
    "        positive_guidance_field='positive_guidance',\n",
    "        negative_guidance_field='negative_guidance'),\n",
    "    NormalizeIntensityd(keys='image', subtrahend=208.0, divisor=388.0),\n",
    "    AddGuidanceSignal(\n",
    "        field='image',\n",
    "        positive_guidance_field='positive_guidance',\n",
    "        negative_guidance_field='negative_guidance'),\n",
    "    ToTensord(keys=['image', 'label'])\n",
    "])\n",
    "\n",
    "interaction_transforms = Compose([\n",
    "    Activationsd(keys='pred', sigmoid=True),\n",
    "    ToNumpyd(keys=['image', 'label', 'pred', 'positive_guidance', 'negative_guidance', 'p_interact']),\n",
    "    InteractionFindDiscrepancyRegions(\n",
    "        prediction_field='pred',\n",
    "        label_field='label',\n",
    "        positive_disparity_field='positive_disparity',\n",
    "        negative_disparity_field='negative_disparity'),\n",
    "    InteractionAddRandomGuidance(\n",
    "        label_field='label',\n",
    "        positive_guidance_field='positive_guidance',\n",
    "        negative_guidance_field='negative_guidance',\n",
    "        positive_disparity_field='positive_disparity',\n",
    "        negative_disparity_field='negative_disparity',\n",
    "        p_interact_field='p_interact'),\n",
    "    InteractionAddGuidanceSignal(\n",
    "        field='image',\n",
    "        positive_guidance_field='positive_guidance',\n",
    "        negative_guidance_field='negative_guidance'),\n",
    "    ToTensord(keys=['image', 'label'])\n",
    "])\n",
    "\n",
    "post_transforms = Compose([\n",
    "    Activationsd(keys='pred', sigmoid=True),\n",
    "    AsDiscreted(keys='pred', threshold_values=True, logit_thresh=0.5)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = DeepgrowDataset(\n",
    "    dimension=2,\n",
    "    pixdim=[1.0, 1.0, 1.0],\n",
    "    spatial_size=[512, 512],\n",
    "    root_dir=root_dir,\n",
    "    transform=pre_transforms,\n",
    "    section=\"training\",\n",
    "    cache_num=0,\n",
    "    limit=1,\n",
    "    task=\"Task09_Spleen\"\n",
    ")\n",
    "train_loader = DataLoader(train_ds, batch_size=4, shuffle=True, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = DeepgrowDataset(\n",
    "    dimension=2,\n",
    "    pixdim=[1.0, 1.0, 1.0],\n",
    "    spatial_size=[512, 512],\n",
    "    root_dir=root_dir,\n",
    "    transform=pre_transforms,\n",
    "    section=\"validation\",\n",
    "    cache_num=0,\n",
    "    limit=1,\n",
    "    task=\"Task09_Spleen\"\n",
    ")\n",
    "val_loader = DataLoader(val_ds, batch_size=4, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "network = network.to(device)\n",
    "\n",
    "output = os.path.join(root_dir, 'output')\n",
    "os.makedirs(output, exist_ok=True)\n",
    "\n",
    "save_interval = 5\n",
    "max_val_interactions = 5\n",
    "max_train_interactions = 15\n",
    "learning_rate = 0.0001\n",
    "epochs = 5\n",
    "amp = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define event-handlers for engine\n",
    "val_handlers = [\n",
    "    StatsHandler(output_transform=lambda x: None),\n",
    "    TensorBoardStatsHandler(log_dir=output, output_transform=lambda x: None),\n",
    "    DeepgrowStatsHandler(log_dir=output, tag_name='val_dice'),\n",
    "    CheckpointSaver(save_dir=output, save_dict={\"net\": network}, save_key_metric=True, save_final=True,\n",
    "                    save_interval=save_interval, final_filename='model.pt')\n",
    "]\n",
    "\n",
    "evaluator = SupervisedEvaluator(\n",
    "    device=device,\n",
    "    val_data_loader=val_loader,\n",
    "    network=network,\n",
    "    iteration_update=Interaction(\n",
    "        transforms=interaction_transforms,\n",
    "        max_interactions=max_val_interactions,\n",
    "        train=False),\n",
    "    inferer=SimpleInferer(),\n",
    "    post_transform=post_transforms,\n",
    "    key_val_metric={\n",
    "        \"val_dice\": MeanDice(\n",
    "            include_background=False,\n",
    "            output_transform=lambda x: (x[\"pred\"], x[\"label\"])\n",
    "        )\n",
    "    },\n",
    "    val_handlers=val_handlers\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = DiceLoss(sigmoid=True, squared_pred=True)\n",
    "optimizer = torch.optim.Adam(network.parameters(), learning_rate)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5000, gamma=0.1)\n",
    "\n",
    "train_handlers = [\n",
    "    LrScheduleHandler(lr_scheduler=lr_scheduler, print_lr=True),\n",
    "    ValidationHandler(validator=evaluator, interval=1, epoch_level=True),\n",
    "    StatsHandler(tag_name=\"train_loss\", output_transform=lambda x: x[\"loss\"]),\n",
    "    TensorBoardStatsHandler(log_dir=output, tag_name=\"train_loss\", output_transform=lambda x: x[\"loss\"]),\n",
    "    CheckpointSaver(save_dir=output, save_dict={\"net\": network, \"opt\": optimizer, \"lr\": lr_scheduler},\n",
    "                    save_interval=save_interval, save_final=True, final_filename='checkpoint.pt'),\n",
    "]\n",
    "trainer = SupervisedTrainer(\n",
    "    device=device,\n",
    "    max_epochs=epochs,\n",
    "    train_data_loader=train_loader,\n",
    "    network=network,\n",
    "    iteration_update=Interaction(\n",
    "        transforms=interaction_transforms,\n",
    "        max_interactions=max_train_interactions,\n",
    "        train=True),\n",
    "    optimizer=optimizer,\n",
    "    loss_function=loss_function,\n",
    "    inferer=SimpleInferer(),\n",
    "    post_transform=post_transforms,\n",
    "    amp=amp,\n",
    "    key_train_metric={\n",
    "        \"train_dice\": MeanDice(\n",
    "            include_background=False,\n",
    "            output_transform=lambda x: (x[\"pred\"], x[\"label\"])\n",
    "        )\n",
    "    },\n",
    "    train_handlers=train_handlers,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "trainer.run()\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total Training Time {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
