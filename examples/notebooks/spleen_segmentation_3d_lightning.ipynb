{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spleen 3D segmentation with MONAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial demonstrates how MONAI can be used in conjunction with the [PyTorch Lightning](https://github.com/PyTorchLightning/pytorch-lightning) framework.\n",
    "\n",
    "We demonstrate use of the following MONAI features:\n",
    "1. Transforms for dictionary format data.\n",
    "2. Loading Nifti images with metadata.\n",
    "3. Add channel dim to the data if no channel dimension.\n",
    "4. Scaling medical image intensity with expected range.\n",
    "5. Croping out a batch of balanced images based on  the positive / negative label ratio.\n",
    "6. Cache IO and transforms to accelerate training and validation.\n",
    "7. Use of a a 3D UNet model, Dice loss function, and mean Dice metric for a 3D segmentation task.\n",
    "8. The sliding window inference method.\n",
    "9. Deterministic training for reproducibility.\n",
    "\n",
    "The Spleen dataset can be downloaded from http://medicaldecathlon.com/.\n",
    "\n",
    "![spleen](http://medicaldecathlon.com/img/spleen0.png)\n",
    "\n",
    "\n",
    "Target: Spleen  \n",
    "Modality: CT  \n",
    "Size: 61 3D volumes (41 Training + 20 Testing)  \n",
    "Source: Memorial Sloan Kettering Cancer Center  \n",
    "Challenge: Large ranging foreground size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the usual MONAI requirements you will need Lightning installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install pytorch-lightning\n",
    "! pip install ipywidgets\n",
    "! jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2020 MONAI Consortium\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import monai\n",
    "from monai.transforms import \\\n",
    "    Compose, LoadNiftid, AddChanneld, ScaleIntensityRanged, RandCropByPosNegLabeld, \\\n",
    "    CropForegroundd, RandAffined, Spacingd, Orientationd, ToTensord\n",
    "from monai.data import list_data_collate\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.networks.layers import Norm\n",
    "from monai.metrics import compute_meandice\n",
    "from monai.utils import set_determinism\n",
    "from pytorch_lightning import LightningModule, Trainer, loggers\n",
    "from pytorch_lightning.callbacks.model_checkpoint import ModelCheckpoint\n",
    "\n",
    "monai.config.print_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the LightningModule\n",
    "\n",
    "The LightningModule contains a refactoring of your training code. The following module is a refactoring of the code in `spleen_segmentation_3d.ipynb`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._model = monai.networks.nets.UNet(dimensions=3, in_channels=1, out_channels=2,\n",
    "                                               channels=(16, 32, 64, 128, 256),strides=(2, 2, 2, 2),\n",
    "                                               num_res_units=2, norm=Norm.BATCH)\n",
    "        self.loss_function = monai.losses.DiceLoss(to_onehot_y=True, softmax=True)\n",
    "        self.best_val_dice = 0\n",
    "        self.best_val_epoch = 0\n",
    "\n",
    "    \n",
    "    def forward(self, x): \n",
    "        return self._model(x)\n",
    "    \n",
    "    def prepare_data(self):\n",
    "        # set up the correct data path\n",
    "        data_root = '/workspace/data/medical/Task09_Spleen'\n",
    "        train_images = sorted(glob.glob(os.path.join(data_root, 'imagesTr', '*.nii.gz')))\n",
    "        train_labels = sorted(glob.glob(os.path.join(data_root, 'labelsTr', '*.nii.gz')))\n",
    "        data_dicts = [{'image': image_name, 'label': label_name}\n",
    "                      for image_name, label_name in zip(train_images, train_labels)]\n",
    "        train_files, val_files = data_dicts[:-9], data_dicts[-9:]\n",
    "\n",
    "        # set deterministic training for reproducibility\n",
    "        set_determinism(seed=0)\n",
    "\n",
    "        # define the data transforms\n",
    "        train_transforms = Compose([\n",
    "            LoadNiftid(keys=['image', 'label']),\n",
    "            AddChanneld(keys=['image', 'label']),\n",
    "            Spacingd(keys=['image', 'label'], pixdim=(1.5, 1.5, 2.), mode=('bilinear', 'nearest')),\n",
    "            Orientationd(keys=['image', 'label'], axcodes='RAS'),\n",
    "            ScaleIntensityRanged(keys=['image'], a_min=-57, a_max=164, b_min=0.0, b_max=1.0, clip=True),\n",
    "            CropForegroundd(keys=['image', 'label'], source_key='image'),\n",
    "            # randomly crop out patch samples from big image based on pos / neg ratio\n",
    "            # the image centers of negative samples must be in valid image area\n",
    "            RandCropByPosNegLabeld(keys=['image', 'label'], label_key='label', spatial_size=(96, 96, 96), pos=1, \n",
    "                                   neg=1, num_samples=4, image_key='image', image_threshold=0),\n",
    "            # user can also add other random transforms\n",
    "            # RandAffined(keys=['image', 'label'], mode=('bilinear', 'nearest'), prob=1.0, spatial_size=(96, 96, 96),\n",
    "            #             rotate_range=(0, 0, np.pi/15), scale_range=(0.1, 0.1, 0.1)),\n",
    "            ToTensord(keys=['image', 'label'])\n",
    "        ])\n",
    "        val_transforms = Compose([\n",
    "            LoadNiftid(keys=['image', 'label']),\n",
    "            AddChanneld(keys=['image', 'label']),\n",
    "            Spacingd(keys=['image', 'label'], pixdim=(1.5, 1.5, 2.), mode=('bilinear', 'nearest')),\n",
    "            Orientationd(keys=['image', 'label'], axcodes='RAS'),\n",
    "            ScaleIntensityRanged(keys=['image'], a_min=-57, a_max=164, b_min=0.0, b_max=1.0, clip=True),\n",
    "            CropForegroundd(keys=['image', 'label'], source_key='image'),\n",
    "            ToTensord(keys=['image', 'label'])\n",
    "        ])\n",
    "\n",
    "        # we use cached datasets - these are 10x faster than regular datasets\n",
    "        self.train_ds = monai.data.CacheDataset(\n",
    "            data=train_files, transform=train_transforms, cache_rate=1.0, num_workers=4\n",
    "        )\n",
    "        self.val_ds = monai.data.CacheDataset(\n",
    "            data=val_files, transform=val_transforms, cache_rate=1.0, num_workers=4\n",
    "        )\n",
    "        #self.train_ds = monai.data.Dataset(data=train_files, transform=train_transforms)\n",
    "        #self.val_ds = monai.data.Dataset(data=val_files, transform=val_transforms)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        train_loader = DataLoader(self.train_ds, batch_size=2, shuffle=True,\n",
    "                                  num_workers=4, collate_fn=list_data_collate)\n",
    "        return train_loader\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        val_loader = DataLoader(self.val_ds, batch_size=1, num_workers=4)\n",
    "        return val_loader\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self._model.parameters(), 1e-4)\n",
    "        return optimizer\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, labels = batch['image'], batch['label']\n",
    "        output = self.forward(images)\n",
    "        loss = self.loss_function(output, labels)\n",
    "        tensorboard_logs = {'train_loss': loss.item()}\n",
    "        return {'loss': loss, 'log': tensorboard_logs}\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, labels = batch['image'], batch['label']\n",
    "        roi_size = (160, 160, 160)\n",
    "        sw_batch_size = 4\n",
    "        outputs = sliding_window_inference(images, roi_size, sw_batch_size, self.forward)\n",
    "        loss = self.loss_function(outputs, labels)\n",
    "        value = compute_meandice(y_pred=outputs, y=labels, include_background=False,\n",
    "                                 to_onehot_y=True, mutually_exclusive=True)\n",
    "        return {'val_loss': loss, 'val_dice': value}\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        val_dice, val_loss, num_items = 0, 0, 0\n",
    "        for output in outputs:\n",
    "            val_dice += output['val_dice'].sum().item()\n",
    "            val_loss += output['val_loss'].sum().item()\n",
    "            num_items += len(output['val_dice'])\n",
    "        mean_val_dice = torch.tensor(val_dice / num_items)\n",
    "        mean_val_loss = torch.tensor(val_loss / num_items)\n",
    "        tensorboard_logs = {'val_dice': mean_val_dice, 'val_loss': mean_val_loss}\n",
    "        if mean_val_dice > self.best_val_dice:\n",
    "            self.best_val_dice = mean_val_dice\n",
    "            self.best_val_epoch = self.current_epoch\n",
    "        print(f\"current epoch: {self.current_epoch} current mean dice: {mean_val_dice:.4f}\"\n",
    "              f\"\\nbest mean dice: {self.best_val_dice:.4f} at epoch: {self.best_val_epoch}\")\n",
    "        return {'log': tensorboard_logs}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# initialise the LightningModule\n",
    "net = Net()\n",
    "\n",
    "# set up loggers and checkpoints\n",
    "tb_logger = loggers.TensorBoardLogger(save_dir='logs')\n",
    "checkpoint_callback = ModelCheckpoint(filepath='logs/{epoch}-{val_loss:.2f}-{val_dice:.2f}')\n",
    "\n",
    "# initialise Lightning's trainer. \n",
    "trainer = Trainer(gpus=[0],\n",
    "                  max_epochs=600,\n",
    "                  logger=tb_logger,\n",
    "                  checkpoint_callback=checkpoint_callback,\n",
    "                  show_progress_bar=False,\n",
    "                  num_sanity_val_steps=1\n",
    "                 )\n",
    "# train\n",
    "trainer.fit(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"train completed, best_metric: {net.best_val_dice:.4f} at epoch {net.best_val_epoch}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View training in tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir='logs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check best model output with the input image and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "net.eval()\n",
    "device = torch.device('cuda:0')\n",
    "with torch.no_grad():\n",
    "    for i, val_data in enumerate(net.val_dataloader()):\n",
    "        roi_size = (160, 160, 160)\n",
    "        sw_batch_size = 4\n",
    "        val_outputs = sliding_window_inference(val_data['image'].to(device), roi_size, sw_batch_size, net)\n",
    "        # plot the slice [:, :, 80]\n",
    "        plt.figure('check', (18, 6))\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.title(f\"image {str(i)}\")\n",
    "        plt.imshow(val_data['image'][0, 0, :, :, 80], cmap='gray')\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.title(f\"label {str(i)}\")\n",
    "        plt.imshow(val_data['label'][0, 0, :, :, 80])\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.title(f\"output {str(i)}\")\n",
    "        plt.imshow(torch.argmax(val_outputs, dim=1).detach().cpu()[0, :, :, 80])\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}