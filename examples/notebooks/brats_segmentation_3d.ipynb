{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brain tumor 3D segmentation with MONAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial shows how to construct a training workflow of multi-labels segmentation task.  \n",
    "And it contains below features:\n",
    "1. Transforms for dictionary format data.\n",
    "2. Define a new transform according to MONAI transform API.\n",
    "3. Load Nifti image with metadata, load a list of images and stack them.\n",
    "4. Randomly adjust intensity for data augmentation.\n",
    "5. Cache IO and transforms to accelerate training and validation.\n",
    "6. 3D UNet model, Dice loss function, Mean Dice metric for 3D segmentation task.\n",
    "7. Deterministic training for reproducibility.\n",
    "\n",
    "The Brain tumor dataset can be downloaded from http://medicaldecathlon.com/.  \n",
    "Target: Gliomas segmentation necrotic/active tumour and oedema  \n",
    "Modality: Multimodal multisite MRI data (FLAIR, T1w, T1gd,T2w)  \n",
    "Size: 750 4D volumes (484 Training + 266 Testing)  \n",
    "Source: BRATS 2016 and 2017 datasets.  \n",
    "Challenge: Complex and heterogeneously-located targets\n",
    "\n",
    "Below figure shows image patches with the tumor sub-regions that are annotated in the different modalities (top left) and the final labels for the whole dataset (right). (Figure taken from the [BraTS IEEE TMI paper](https://ieeexplore.ieee.org/document/6975210/))  \n",
    "![image](./images/brats_tasks.png)\n",
    "The image patches show from left to right:\n",
    "1. the whole tumor (yellow) visible in T2-FLAIR (Fig.A).\n",
    "2. the tumor core (red) visible in T2 (Fig.B).\n",
    "3. the enhancing tumor structures (light blue) visible in T1Gd, surrounding the cystic/necrotic components of the core (green) (Fig. C).\n",
    "4. The segmentations are combined to generate the final labels of the tumor sub-regions (Fig.D): edema (yellow), non-enhancing solid core (red), necrotic/cystic core (green), enhancing core (blue)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2020 MONAI Consortium\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from monai.transforms import \\\n",
    "    MapTransform, Compose, LoadNiftid, AsChannelFirstd, Spacingd, Orientationd, \\\n",
    "    RandSpatialCropd, RandFlipd, NormalizeIntensityd, RandScaleIntensityd, \\\n",
    "    RandShiftIntensityd, CenterSpatialCropd, ToTensord\n",
    "from monai.data import DataLoader\n",
    "from monai.apps import DecathlonDataset\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.networks.nets import UNet\n",
    "from monai.losses import DiceLoss\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.utils import set_determinism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set deterministic training for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_determinism(seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a new transform to convert brain tumor labels\n",
    "Here we convert the multi-classes labels into multi-labels segmentation task in One-Hot format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvertToMultiChannelBasedOnBratsClassesd(MapTransform):\n",
    "    \"\"\"\n",
    "    Convert labels to multi channels based on brats classes:\n",
    "    label 1 is the peritumoral edema\n",
    "    label 2 is the GD-enhancing tumor\n",
    "    label 3 is the necrotic and non-enhancing tumor core\n",
    "    The possible classes are TC (Tumor core), WC (Whole tumor)\n",
    "    and ET (Enhancing tumor).\n",
    "\n",
    "    \"\"\"\n",
    "    def __call__(self, data):\n",
    "        d = dict(data)\n",
    "        for key in self.keys:\n",
    "            result = list()\n",
    "            # merge label 2 and label 3 to construct TC\n",
    "            result.append(np.logical_or(d[key] == 2, d[key] == 3))\n",
    "            # merge labels 1, 2 and 3 to construct WC\n",
    "            result.append(np.logical_or(np.logical_or(d[key] == 2, d[key] == 3), d[key] == 1))\n",
    "            # label 2 is ET\n",
    "            result.append(d[key] == 2)\n",
    "            d[key] = np.stack(result, axis=0).astype(np.float32)\n",
    "        return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup transforms for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = Compose([\n",
    "    # load 4 Nifti images and stack them together\n",
    "    LoadNiftid(keys=['image', 'label']),\n",
    "    AsChannelFirstd(keys='image'),\n",
    "    ConvertToMultiChannelBasedOnBratsClassesd(keys='label'),\n",
    "    Spacingd(keys=['image', 'label'], pixdim=(1.5, 1.5, 2.), mode=('bilinear', 'nearest')),\n",
    "    Orientationd(keys=['image', 'label'], axcodes='RAS'),\n",
    "    RandSpatialCropd(keys=['image', 'label'], roi_size=[128, 128, 64], random_size=False),\n",
    "    RandFlipd(keys=['image', 'label'], prob=0.5, spatial_axis=0),\n",
    "    NormalizeIntensityd(keys='image', nonzero=True, channel_wise=True),\n",
    "    RandScaleIntensityd(keys='image', factors=0.1, prob=0.5),\n",
    "    RandShiftIntensityd(keys='image', offsets=0.1, prob=0.5),\n",
    "    ToTensord(keys=['image', 'label'])\n",
    "])\n",
    "val_transform = Compose([\n",
    "    LoadNiftid(keys=['image', 'label']),\n",
    "    AsChannelFirstd(keys='image'),\n",
    "    ConvertToMultiChannelBasedOnBratsClassesd(keys='label'),\n",
    "    Spacingd(keys=['image', 'label'], pixdim=(1.5, 1.5, 2.), mode=('bilinear', 'nearest')),\n",
    "    Orientationd(keys=['image', 'label'], axcodes='RAS'),\n",
    "    CenterSpatialCropd(keys=['image', 'label'], roi_size=[128, 128, 64]),\n",
    "    NormalizeIntensityd(keys='image', nonzero=True, channel_wise=True),\n",
    "    ToTensord(keys=['image', 'label'])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quickly load data with DecathlonDataset\n",
    "Here we use `DecathlonDataset` to automatically download and extract the dataset.\n",
    "It inherits MONAI `CacheDataset`, so we set `cache_num=100` to cache 100 items for training and use the defaut args to cache all the items for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/workspace/data/medical'\n",
    "train_ds = DecathlonDataset(root_dir=root_dir, task='Task01_BrainTumour', transform=train_transform,\n",
    "                            section='training', download=True, num_workers=4, cache_num=100)\n",
    "train_loader = DataLoader(train_ds, batch_size=2, shuffle=True, num_workers=4)\n",
    "val_ds = DecathlonDataset(root_dir=root_dir, task='Task01_BrainTumour', transform=val_transform,\n",
    "                          section='validation', download=False, num_workers=4)\n",
    "val_loader = DataLoader(val_ds, batch_size=2, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check data shape and visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick one image from DecathlonDataset to visualize and check the 4 channels\n",
    "print(f\"image shape: {val_ds[9]['image'].shape}\")\n",
    "plt.figure('image', (24, 6))\n",
    "for i in range(4):\n",
    "    plt.subplot(1, 4, i + 1)\n",
    "    plt.title(f\"image channel {str(i)}\")\n",
    "    plt.imshow(val_ds[9]['image'][i, :, :, 20].detach().cpu(), cmap='gray')\n",
    "plt.show()\n",
    "# also visualize the 3 channels label corresponding to this image\n",
    "print(f\"label shape: {val_ds[9]['label'].shape}\")\n",
    "plt.figure('label', (18, 6))\n",
    "for i in range(3):\n",
    "    plt.subplot(1, 3, i + 1)\n",
    "    plt.title(f\"label channel {str(i)}\")\n",
    "    plt.imshow(val_ds[9]['label'][i, :, :, 20].detach().cpu())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model, Loss, Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard PyTorch program style: create UNet, DiceLoss and Adam optimizer\n",
    "device = torch.device('cuda:0')\n",
    "model = UNet(dimensions=3, in_channels=4, out_channels=3, channels=(16, 32, 64, 128, 256),\n",
    "             strides=(2, 2, 2, 2), num_res_units=2).to(device)\n",
    "loss_function = DiceLoss(to_onehot_y=False, sigmoid=True, squared_pred=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), 1e-4, weight_decay=1e-5, amsgrad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute a typical PyTorch training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epoch_num = 180\n",
    "val_interval = 2\n",
    "best_metric = -1\n",
    "best_metric_epoch = -1\n",
    "epoch_loss_values = list()\n",
    "metric_values = list()\n",
    "metric_values_tc = list()\n",
    "metric_values_wt = list()\n",
    "metric_values_et = list()\n",
    "for epoch in range(epoch_num):\n",
    "    print('-' * 10)\n",
    "    print(f\"epoch {epoch + 1}/{epoch_num}\")\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    for batch_data in train_loader:\n",
    "        step += 1\n",
    "        inputs, labels = batch_data['image'].to(device), batch_data['label'].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        print(f\"{step}/{len(train_ds) // train_loader.batch_size}, train_loss: {loss.item():.4f}\")\n",
    "    epoch_loss /= step\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    if (epoch + 1) % val_interval == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            dice_metric = DiceMetric(include_background=True, sigmoid=True, reduction='mean')\n",
    "            metric_sum = metric_sum_tc = metric_sum_wt = metric_sum_et = 0.\n",
    "            metric_count = metric_count_tc = metric_count_wt = metric_count_et = 0\n",
    "            for val_data in val_loader:\n",
    "                val_inputs, val_labels = val_data['image'].to(device), val_data['label'].to(device)\n",
    "                val_outputs = model(val_inputs)\n",
    "                # compute overall mean dice\n",
    "                value = dice_metric(y_pred=val_outputs, y=val_labels)\n",
    "                not_nans = dice_metric.not_nans.item()\n",
    "                metric_count += not_nans\n",
    "                metric_sum += value.item() * not_nans\n",
    "                # compute mean dice for TC\n",
    "                value_tc = dice_metric(y_pred=val_outputs[:, 0 : 1], y=val_labels[:, 0 : 1])\n",
    "                not_nans = dice_metric.not_nans.item()\n",
    "                metric_count_tc += not_nans\n",
    "                metric_sum_tc += value_tc.item() * not_nans\n",
    "                # compute mean dice for WT\n",
    "                value_wt = dice_metric(y_pred=val_outputs[:, 1 : 2], y=val_labels[:, 1 : 2])\n",
    "                not_nans = dice_metric.not_nans.item()\n",
    "                metric_count_wt += not_nans\n",
    "                metric_sum_wt += value_wt.item() * not_nans\n",
    "                # compute mean dice for ET\n",
    "                value_et = dice_metric(y_pred=val_outputs[:, 2 : 3], y=val_labels[:, 2 : 3])\n",
    "                not_nans = dice_metric.not_nans.item()\n",
    "                metric_count_et += not_nans\n",
    "                metric_sum_et += value_et.item() * not_nans\n",
    "                \n",
    "            metric = metric_sum / metric_count\n",
    "            metric_values.append(metric)\n",
    "            metric_tc = metric_sum_tc / metric_count_tc\n",
    "            metric_values_tc.append(metric_tc)\n",
    "            metric_wt = metric_sum_wt / metric_count_wt\n",
    "            metric_values_wt.append(metric_wt)\n",
    "            metric_et = metric_sum_et / metric_count_et\n",
    "            metric_values_et.append(metric_et)\n",
    "            if metric > best_metric:\n",
    "                best_metric = metric\n",
    "                best_metric_epoch = epoch + 1\n",
    "                torch.save(model.state_dict(), 'best_metric_model.pth')\n",
    "                print('saved new best metric model')\n",
    "            print(f\"current epoch: {epoch + 1} current mean dice: {metric:.4f}\"\n",
    "                  f\" tc: {metric_tc:.4f} wt: {metric_wt:.4f} et: {metric_et:.4f}\"\n",
    "                  f\"\\nbest mean dice: {best_metric:.4f} at epoch: {best_metric_epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the loss and metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure('train', (12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Epoch Average Loss')\n",
    "x = [i + 1 for i in range(len(epoch_loss_values))]\n",
    "y = epoch_loss_values\n",
    "plt.xlabel('epoch')\n",
    "plt.plot(x, y, color='red')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Val Mean Dice')\n",
    "x = [val_interval * (i + 1) for i in range(len(metric_values))]\n",
    "y = metric_values\n",
    "plt.xlabel('epoch')\n",
    "plt.plot(x, y, color='green')\n",
    "plt.show()\n",
    "\n",
    "plt.figure('train', (18, 6))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title('Val Mean Dice TC')\n",
    "x = [val_interval * (i + 1) for i in range(len(metric_values_tc))]\n",
    "y = metric_values_tc\n",
    "plt.xlabel('epoch')\n",
    "plt.plot(x, y, color='blue')\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title('Val Mean Dice WT')\n",
    "x = [val_interval * (i + 1) for i in range(len(metric_values_wt))]\n",
    "y = metric_values_wt\n",
    "plt.xlabel('epoch')\n",
    "plt.plot(x, y, color='brown')\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title('Val Mean Dice ET')\n",
    "x = [val_interval * (i + 1) for i in range(len(metric_values_et))]\n",
    "y = metric_values_et\n",
    "plt.xlabel('epoch')\n",
    "plt.plot(x, y, color='purple')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check best model output with the input image and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('best_metric_model.pth'))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # select one image to evaluate and visualize the model output\n",
    "    val_input = val_ds[6]['image'].unsqueeze(0).to(device)\n",
    "    val_output = model(val_input)\n",
    "    plt.figure('image', (24, 6))\n",
    "    for i in range(4):\n",
    "        plt.subplot(1, 4, i + 1)\n",
    "        plt.title(f\"image channel {str(i)}\")\n",
    "        plt.imshow(val_ds[6]['image'][i, :, :, 20].detach().cpu(), cmap='gray')\n",
    "    plt.show()\n",
    "    # visualize the 3 channels label corresponding to this image\n",
    "    plt.figure('label', (18, 6))\n",
    "    for i in range(3):\n",
    "        plt.subplot(1, 3, i + 1)\n",
    "        plt.title(f\"label channel {str(i)}\")\n",
    "        plt.imshow(val_ds[6]['label'][i, :, :, 20].detach().cpu())\n",
    "    plt.show()\n",
    "    # visualize the 3 channels model output corresponding to this image\n",
    "    plt.figure('output', (18, 6))\n",
    "    for i in range(3):\n",
    "        plt.subplot(1, 3, i + 1)\n",
    "        plt.title(f\"output channel {str(i)}\")\n",
    "        plt.imshow((val_output[0, i, :, :, 20].sigmoid() >= 0.5).float().detach().cpu())\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}