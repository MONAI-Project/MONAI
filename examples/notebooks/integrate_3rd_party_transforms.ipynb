{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrate 3rd party transforms into MONAI program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial shows how to integrate 3rd party transforms into MONAI program.  \n",
    "Mainly shows transforms from `BatchGenerator`, `TorchIO`, `Rising` and `ITK`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install batchgenerators==0.20.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install torchio==0.17.21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install rising==0.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install itk==5.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you use TorchIO for your research, please cite the following paper:\n",
      "Pérez-García et al., TorchIO: a Python library for efficient loading,\n",
      "preprocessing, augmentation and patch-based sampling of medical images\n",
      "in deep learning. Link: https://arxiv.org/abs/2003.04696\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Copyright 2020 MONAI Consortium\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from monai.transforms import \\\n",
    "    LoadNiftid, AddChanneld, ScaleIntensityRanged, CropForegroundd, \\\n",
    "    Spacingd, Orientationd, SqueezeDimd, ToTensord, adaptor, Compose\n",
    "import monai\n",
    "from monai.utils import set_determinism\n",
    "from batchgenerators.transforms.color_transforms import ContrastAugmentationTransform\n",
    "from torchio.transforms import RescaleIntensity\n",
    "from rising.random import DiscreteParameter\n",
    "from rising.transforms import Mirror\n",
    "from itk import median_image_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set MSD Spleen dataset path\n",
    "The Spleen dataset can be downloaded from http://medicaldecathlon.com/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = '/workspace/data/medical/Task09_Spleen'\n",
    "train_images = sorted(glob.glob(os.path.join(data_root, 'imagesTr', '*.nii.gz')))\n",
    "train_labels = sorted(glob.glob(os.path.join(data_root, 'labelsTr', '*.nii.gz')))\n",
    "data_dicts = [{'image': image_name, 'label': label_name}\n",
    "              for image_name, label_name in zip(train_images, train_labels)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set deterministic training for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_determinism(seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup MONAI transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monai_transforms = [\n",
    "    LoadNiftid(keys=['image', 'label']),\n",
    "    AddChanneld(keys=['image', 'label']),\n",
    "    Spacingd(keys=['image', 'label'], pixdim=(1.5, 1.5, 2.), mode=('bilinear', 'nearest')),\n",
    "    Orientationd(keys=['image', 'label'], axcodes='RAS'),\n",
    "    ScaleIntensityRanged(keys=['image'], a_min=-57, a_max=164, b_min=0.0, b_max=1.0, clip=True),\n",
    "    CropForegroundd(keys=['image', 'label'], source_key='image')\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup BatchGenerator transforms\n",
    "Note:\n",
    "1. BatchGenerator requires the arg is `**data`, can't compose with MONAI transforms directly, need `adaptor`.\n",
    "2. BatchGenerator requires data shape is [B, C, H, W, D], MONAI requires [C, H, W, D]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_generator_transforms = ContrastAugmentationTransform(data_key='image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup TorchIO transforms\n",
    "Note:\n",
    "1. The TorchIO transforms can support MONAI dict input data directly.\n",
    "2. It can handle PyTorch Tensor data(shape: [C, H, W, D]), so used it to handle Tensor in this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchio_transforms = RescaleIntensity(\n",
    "    out_min_max=(0., 1.),\n",
    "    percentiles=(0.05, 99.5),\n",
    "    keys=['image'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Rising transforms\n",
    "Note:\n",
    "1. Rising inherits from PyTorch `nn.Module`, expected input data type is PyTorch Tensor, so can only work after `ToTensor`.\n",
    "2. Rising requires data shape is [B, C, H, W, D], MONAI requires [C, H, W, D].\n",
    "3. Rising requires the arg is `**data`, need `adaptor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rising_transforms = Mirror(dims=DiscreteParameter((0, 1, 2)), keys=['image', 'label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup ITK transforms\n",
    "Note:\n",
    "1. ITK transform function API has several args(not only `data`), need to set args in wrapper before Compose.\n",
    "2. If input data is Numpy, ITK can't support dict type, need wrapper to convert the format.\n",
    "3. ITK expects input shape [H, W, [D]], so handle every channel and stack the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def itk_transforms(x):\n",
    "    smoothed = list()\n",
    "    for channel in x['image']:\n",
    "        smoothed.append(median_image_filter(channel, radius=2))\n",
    "    x['image'] = np.stack(smoothed)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compose all transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = Compose(monai_transforms + [\n",
    "    itk_transforms,\n",
    "    # add another dim as BatchGenerator and Rising expects shape [B, C, H, W, D]\n",
    "    AddChanneld(keys=['image', 'label']),\n",
    "    adaptor(batch_generator_transforms, {'image': 'image'}),\n",
    "    ToTensord(keys=['image', 'label']),\n",
    "    adaptor(rising_transforms, {'image': 'image', 'label': 'label'}),\n",
    "    # squeeze shape from [B, C, H, W, D] to [C, H, W, D] for TorchIO transforms\n",
    "    SqueezeDimd(keys=['image', 'label'], dim=0),\n",
    "    torchio_transforms,\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check transforms in DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_ds = monai.data.Dataset(data=data_dicts, transform=transform)\n",
    "check_loader = monai.data.DataLoader(check_ds, batch_size=1)\n",
    "check_data = monai.utils.misc.first(check_loader)\n",
    "image, label = (check_data['image'][0][0], check_data['label'][0][0])\n",
    "print(f\"image shape: {image.shape}, label shape: {label.shape}\")\n",
    "# plot the slice [:, :, 80]\n",
    "plt.figure('check', (12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('image')\n",
    "plt.imshow(image[:, :, 80], cmap='gray')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('label')\n",
    "plt.imshow(label[:, :, 80])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}