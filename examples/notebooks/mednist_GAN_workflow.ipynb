{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN Workflow Engine with the MedNIST Dataset\n",
    "\n",
    "The MONAI framework can be used to easily design, train, and evaluate generative adversarial networks. This notebook exemplifies using MONAI components to design and train a simple GAN model to reconstruct images of Hand CT scans.\n",
    "\n",
    "Read the [MONAI Mednist GAN Tutorial](https://github.com/Project-MONAI/MONAI/blob/master/examples/notebooks/mednist_GAN_tutorial.ipynb) for details about the network architecture and loss functions.\n",
    "\n",
    "**Table of Contents**\n",
    "\n",
    "1. Load libraries\n",
    "2. Initialize MONAI Components\n",
    "    * Create image transform chain\n",
    "    * Create dataset and dataloader\n",
    "    * Define generator and discriminator\n",
    "    * Create training handlers\n",
    "    * Create GanTrainer\n",
    "3. Run Training\n",
    "4. Evaluate Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Project-MONAI/MONAI/blob/master/examples/notebooks/mednist_GAN_workflow.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Prepare python libraries and download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install monai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "from urllib.request import urlopen\n",
    "from io import BytesIO\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import torch\n",
    "\n",
    "import monai\n",
    "from monai.data import CacheDataset, DataLoader, png_writer\n",
    "from monai.networks.nets import Generator, Discriminator\n",
    "from monai.networks import normal_init\n",
    "from monai.engines import GanTrainer\n",
    "from monai.engines.utils import GanKeys as Keys\n",
    "from monai.engines.utils import default_make_latent as make_latent\n",
    "from monai.handlers import StatsHandler, CheckpointSaver, MetricLogger\n",
    "from monai.transforms import (\n",
    "    Compose,\n",
    "    LoadPNGD,\n",
    "    AddChannelD,\n",
    "    ScaleIntensityD,\n",
    "    RandRotateD,\n",
    "    RandFlipD,\n",
    "    RandZoomD,\n",
    "    ToTensorD,\n",
    ")\n",
    "from monai.apps.utils import download_and_extract\n",
    "from monai.utils.misc import set_determinism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "monai.config.print_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the dataset\n",
    "\n",
    "MedNIST dataset information in [MONAI MedNIST Tutorial](https://github.com/Project-MONAI/MONAI/blob/master/examples/notebooks/mednist_tutorial.ipynb) example notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mednist_url = 'https://www.dropbox.com/s/5wwskxctvcxiuea/MedNIST.tar.gz?dl=1'\n",
    "md5_value = \"0bc7306e7427e00ad1c5526a6677552d\"\n",
    "extract_dir = 'data'\n",
    "tar_save_path = os.path.join(extract_dir, \"MedNIST.tar.gz\")\n",
    "download_and_extract(mednist_url, tar_save_path, extract_dir, md5_value)\n",
    "hand_dir = os.path.join(extract_dir, 'MedNIST', 'Hand')\n",
    "training_datadict = [{\"hand\": os.path.join(hand_dir, filename)} for filename in os.listdir(hand_dir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(training_datadict[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Initialize MONAI components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "set_determinism(12345)\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create image transform chain\n",
    "\n",
    "Define the processing pipeline to convert saved disk images into usable Tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadPNGD(keys=[\"hand\"]),\n",
    "        AddChannelD(keys=[\"hand\"]),\n",
    "        ScaleIntensityD(keys=[\"hand\"]),\n",
    "        RandRotateD(keys=[\"hand\"], range_x=15, prob=0.5, keep_size=True),\n",
    "        RandFlipD(keys=[\"hand\"], spatial_axis=0, prob=0.5),\n",
    "        RandZoomD(keys=[\"hand\"], min_zoom=0.9, max_zoom=1.1, prob=0.5),\n",
    "        ToTensorD(keys=[\"hand\"]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataset and dataloader\n",
    "\n",
    "Hold data and present batches during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_dataset = CacheDataset(training_datadict, train_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 300\n",
    "real_dataloader = DataLoader(real_dataset, batch_size=batch_size, shuffle=True, num_workers=10)\n",
    "def prepare_batch(batchdata):\n",
    "    return batchdata[\"hand\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define generator and discriminator\n",
    "\n",
    "Load basic computer vision GAN networks from libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define networks\n",
    "disc_net = Discriminator(\n",
    "    in_shape=(1, 64, 64), channels=(8, 16, 32, 64, 1), strides=(2, 2, 2, 2, 1), num_res_units=1, kernel_size=5\n",
    ").to(device)\n",
    "\n",
    "latent_size = 64\n",
    "gen_net = Generator(\n",
    "    latent_shape=latent_size, start_shape=(latent_size, 8, 8), channels=[32, 16, 8, 1], strides=[2, 2, 2, 1]\n",
    ")\n",
    "gen_net.conv.add_module(\"activation\", torch.nn.Sigmoid())\n",
    "gen_net = gen_net.to(device)\n",
    "\n",
    "# initialize both networks\n",
    "disc_net.apply(normal_init)\n",
    "gen_net.apply(normal_init)\n",
    "\n",
    "# define optimizors\n",
    "learning_rate = 2e-4\n",
    "betas = (0.5, 0.999)\n",
    "disc_opt = torch.optim.Adam(disc_net.parameters(), learning_rate, betas=betas)\n",
    "gen_opt = torch.optim.Adam(gen_net.parameters(), learning_rate, betas=betas)\n",
    "\n",
    "# define loss functions\n",
    "disc_loss_criterion = torch.nn.BCELoss()\n",
    "gen_loss_criterion = torch.nn.BCELoss()\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "\n",
    "def discriminator_loss(gen_images, real_images):\n",
    "    real = real_images.new_full((real_images.shape[0], 1), real_label)\n",
    "    gen = gen_images.new_full((gen_images.shape[0], 1), fake_label)\n",
    "\n",
    "    realloss = disc_loss_criterion(disc_net(real_images), real)\n",
    "    genloss = disc_loss_criterion(disc_net(gen_images.detach()), gen)\n",
    "\n",
    "    return (genloss + realloss) / 2\n",
    "\n",
    "def generator_loss(gen_images):\n",
    "    output = disc_net(gen_images)\n",
    "    cats = output.new_full(output.shape, real_label)\n",
    "    return gen_loss_criterion(output, cats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training handlers\n",
    "\n",
    "Perform operations during model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_dir = \"hand-gan\"\n",
    "\n",
    "metric_logger = MetricLogger(\n",
    "        loss_transform=lambda x: {Keys.GLOSS: x[Keys.GLOSS], Keys.DLOSS: x[Keys.DLOSS]},\n",
    "        metric_transform=lambda x: x \n",
    "    )\n",
    "\n",
    "handlers = [\n",
    "    StatsHandler(\n",
    "        name=\"batch_training_loss\",\n",
    "        output_transform=lambda x: {Keys.GLOSS: x[Keys.GLOSS], Keys.DLOSS: x[Keys.DLOSS]},\n",
    "    ),\n",
    "    CheckpointSaver(\n",
    "        save_dir=run_dir,\n",
    "        save_dict={\"g_net\": gen_net, \"d_net\": disc_net},\n",
    "        save_interval=10,\n",
    "        save_final=True,\n",
    "        epoch_level=True,\n",
    "    ),\n",
    "    metric_logger\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create GanTrainer\n",
    "\n",
    "MONAI Workflow engine for adversarial learning. The components come together here with the GanTrainer.\n",
    "\n",
    "Uses a training loop based on Goodfellow et al. 2014 https://arxiv.org/abs/1406.266. \n",
    "\n",
    "```\n",
    "Training Loop: for each batch of data size m\n",
    "        1. Generate m fakes from random latent codes.\n",
    "        2. Update D with these fakes and current batch reals, repeated d_train_steps times.\n",
    "        3. Generate m fakes from new random latent codes.\n",
    "        4. Update generator with these fakes using discriminator feedback.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_train_steps = 5\n",
    "num_epochs = 50\n",
    "\n",
    "trainer = GanTrainer(\n",
    "    device,\n",
    "    num_epochs,\n",
    "    real_dataloader,\n",
    "    gen_net,\n",
    "    gen_opt,\n",
    "    generator_loss,\n",
    "    disc_net,\n",
    "    disc_opt,\n",
    "    discriminator_loss,\n",
    "    d_prepare_batch=prepare_batch,\n",
    "    d_train_steps=disc_train_steps,\n",
    "    g_update_latents=True,\n",
    "    latent_shape=latent_size,\n",
    "    key_train_metric=None,\n",
    "    train_handlers=handlers,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Results\n",
    "\n",
    "Examine G and D loss curves for collapse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_loss = [loss[Keys.GLOSS] for loss in metric_logger.loss]\n",
    "d_loss = [loss[Keys.DLOSS] for loss in metric_logger.loss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.semilogy(g_loss, label='Generator Loss')\n",
    "plt.semilogy(d_loss, label='Discriminator Loss')\n",
    "plt.grid(True, 'both', 'both')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View image reconstructions\n",
    "With random latent codes view trained generator output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_count = 10\n",
    "test_latents = make_latent(test_img_count, latent_size).to(device)\n",
    "fakes = gen_net(test_latents)\n",
    "\n",
    "fig, axs = plt.subplots(2, (test_img_count//2), figsize=(20, 8))\n",
    "axs = axs.flatten()\n",
    "for i, ax in enumerate(axs):\n",
    "    ax.axis('off')\n",
    "    ax.imshow(fakes[i, 0].cpu().data.numpy(), cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}